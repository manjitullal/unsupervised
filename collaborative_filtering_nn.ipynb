{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "collaborative-filtering-nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjitullal/unsupervised/blob/main/collaborative_filtering_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM6EtTgEIQpp"
      },
      "source": [
        "# Collaborative Filtering with Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzrQG4eKIQpq"
      },
      "source": [
        "In this notebook we will write a matrix factorization model in pytorch to solve a recommendation problem. Then we will write a more general neural model for the same problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbUAN-5hIQpq"
      },
      "source": [
        "The MovieLens dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100004 ratings and 1296 tag applications across 9125 movies. https://grouplens.org/datasets/movielens/. To get the data:\n",
        "\n",
        "`wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O6YJJcsIQpq"
      },
      "source": [
        "## MovieLens dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUlcU-HiIQpq"
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq_904ADIQpq",
        "outputId": "d6c3951b-d716-4117-cb52-a862c3fbf604"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUrtAAfwIQpr"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/datasets/ml-latest-small/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOh0NPWbm-rw",
        "outputId": "22001952-675a-42ca-a511-a28be49967d8"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/datasets/kaggle/kaggle.json ~/.kaggle/\n",
        "! kaggle datasets download -d rounakbanik/the-movies-dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading the-movies-dataset.zip to /content\n",
            " 90% 205M/228M [00:03<00:00, 56.1MB/s]\n",
            "100% 228M/228M [00:04<00:00, 59.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NG4eVzVnCgq",
        "outputId": "311c9f2a-f010-4d45-eb9a-40a13684ee43"
      },
      "source": [
        "! unzip the-movies-dataset.zip -d the-movies-dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  the-movies-dataset.zip\n",
            "  inflating: the-movies-dataset/credits.csv  \n",
            "  inflating: the-movies-dataset/keywords.csv  \n",
            "  inflating: the-movies-dataset/links.csv  \n",
            "  inflating: the-movies-dataset/links_small.csv  \n",
            "  inflating: the-movies-dataset/movies_metadata.csv  \n",
            "  inflating: the-movies-dataset/ratings.csv  \n",
            "  inflating: the-movies-dataset/ratings_small.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RJ1v-IGnuVx"
      },
      "source": [
        "big_data = pd.read_csv(\"/content/the-movies-dataset/ratings.csv\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNA6JnItIQps"
      },
      "source": [
        "data = pd.read_csv(PATH+\"ratings.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "-ixJ0FrSIQps",
        "outputId": "41bc7ab3-ebb7-474b-917f-ea60e03dc8dd"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "x7TtfUuvn-36",
        "outputId": "75adc5c8-895a-4d81-9d38-bda0d461bf73"
      },
      "source": [
        "big_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1425941529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>147</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1425942435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>858</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1425941523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1221</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1425941546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1246</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1425941556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1      110     1.0  1425941529\n",
              "1       1      147     4.5  1425942435\n",
              "2       1      858     5.0  1425941523\n",
              "3       1     1221     5.0  1425941546\n",
              "4       1     1246     5.0  1425941556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6DWfPVaoAuB",
        "outputId": "3316038b-6b6d-4a8e-84f8-16c9e193c156"
      },
      "source": [
        "big_data.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26024289, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EopZLzFxjITG",
        "outputId": "6cea267f-8c73-45cc-8e8a-7c17197d6de7"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100836, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2AICnVyIQps"
      },
      "source": [
        "### Encoding data\n",
        "We enconde the data to have contiguous ids for users and movies. You can think about this as a categorical encoding of our two categorical variables userId and movieId."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bumix2poPwx"
      },
      "source": [
        "data = big_data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0a96614oQy5",
        "outputId": "64bf9da8-55e2-44d0-83fa-dc2085861976"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26024289, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlD_2UktIQps"
      },
      "source": [
        "# split train and validation before encoding\n",
        "np.random.seed(3)\n",
        "msk = np.random.rand(len(data)) < 0.8\n",
        "train = data[msk].copy()\n",
        "val = data[~msk].copy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8ItKW5tIQps"
      },
      "source": [
        "# here is a handy function modified from fast.ai\n",
        "def proc_col(col, train_col=None):\n",
        "    \"\"\"Encodes a pandas column with continous ids. \n",
        "    \"\"\"\n",
        "    if train_col is not None:\n",
        "        uniq = train_col.unique()\n",
        "    else:\n",
        "        uniq = col.unique()\n",
        "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
        "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1u50pTtIQps"
      },
      "source": [
        "def encode_data(df, train=None):\n",
        "    \"\"\" Encodes rating data with continous user and movie ids. \n",
        "    If train is provided, encodes df with the same encoding as train.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for col_name in [\"userId\", \"movieId\"]:\n",
        "        train_col = None\n",
        "        if train is not None:\n",
        "            train_col = train[col_name]\n",
        "        _,col,_ = proc_col(df[col_name], train_col)\n",
        "        df[col_name] = col\n",
        "        df = df[df[col_name] >= 0]\n",
        "    return df"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfzfgx8tIQps"
      },
      "source": [
        "# encoding the train and validation data\n",
        "df_train = encode_data(train)\n",
        "df_val = encode_data(val, train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXD8_Dp_IQps"
      },
      "source": [
        "## Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdTL_-g9IQps"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzTGKWHPIQps"
      },
      "source": [
        "# an Embedding module containing 10 user or item embedding size 3\n",
        "# embedding will be initialized at random\n",
        "embed = nn.Embedding(10, 3)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKsJzkl-IQps",
        "outputId": "7661a0ad-3c4f-486e-fe41-90a0badde3df"
      },
      "source": [
        "# given a list of ids we can \"look up\" the embedding corresponing to each id\n",
        "a = torch.LongTensor([[1,2,0,4,5,1]])\n",
        "embed(a)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6804,  0.6520,  0.0295],\n",
              "         [ 0.2523, -0.7621,  0.6157],\n",
              "         [ 1.8185,  0.0216,  2.6749],\n",
              "         [-0.4554, -1.7967,  0.1572],\n",
              "         [-0.2394,  0.0648, -1.1067],\n",
              "         [ 0.6804,  0.6520,  0.0295]]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0-C4Gs9IQpt"
      },
      "source": [
        "## Matrix factorization model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5pp1YGWIQpt"
      },
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100):\n",
        "        super(MF, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.user_emb.weight.data.uniform_(0, 0.05)\n",
        "        self.item_emb.weight.data.uniform_(0, 0.05)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        u = self.user_emb(u)\n",
        "        v = self.item_emb(v)\n",
        "        return (u*v).sum(1)   "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIa-ITd-IQpt"
      },
      "source": [
        "## Training MF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyVAXtd_IQpt",
        "outputId": "3b3145c2-3926-4350-c2a0-ad2b4c9c88ed"
      },
      "source": [
        "num_users = len(df_train.userId.unique())\n",
        "num_items = len(df_train.movieId.unique())\n",
        "print(num_users, num_items) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "269701 43394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzeVWOtyIQpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e282fb53-3c52-4aeb-e8c4-7410f6b14da5"
      },
      "source": [
        "model = MF(num_users, num_items, emb_size=100) # .cuda() if you have a GPU\n",
        "model.cuda()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MF(\n",
              "  (user_emb): Embedding(269701, 100)\n",
              "  (item_emb): Embedding(43394, 100)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ifCqWGEIQpu"
      },
      "source": [
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for i in range(epochs):\n",
        "        users = torch.LongTensor(df_train.userId.values).cuda()\n",
        "        items = torch.LongTensor(df_train.movieId.values).cuda()\n",
        "        ratings = torch.FloatTensor(df_train.rating.values).cuda()\n",
        "        if unsqueeze:\n",
        "            ratings = ratings.unsqueeze(1)\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss.item()) \n",
        "    test_loss(model, unsqueeze)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na9675usIQpu",
        "outputId": "1b98b80c-c051-4d5e-a8df-7e60fd66c1cd"
      },
      "source": [
        "# Here is what unsqueeze does\n",
        "ratings = torch.FloatTensor(df_train.rating.values)\n",
        "print(ratings.shape)\n",
        "ratings = ratings.unsqueeze(1).cuda()\n",
        "print(ratings.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20819462])\n",
            "torch.Size([20819462, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUzU-MqIQpu"
      },
      "source": [
        "def test_loss(model, unsqueeze=False):\n",
        "    model.eval()\n",
        "    users = torch.LongTensor(df_val.userId.values).cuda()\n",
        "    items = torch.LongTensor(df_val.movieId.values).cuda()\n",
        "    ratings = torch.FloatTensor(df_val.rating.values).cuda()\n",
        "    if unsqueeze:\n",
        "        ratings = ratings.unsqueeze(1)\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "BRCB4RPDIQpu",
        "outputId": "96b0bf5a-1227-4af9-d4a8-173479c8e56c"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-6f2c3de2f8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_epocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-c93cd4e3f4c2>\u001b[0m in \u001b[0;36mtrain_epocs\u001b[0;34m(model, epochs, lr, wd, unsqueeze)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munsqueeze\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-f03215f48849>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, u, v)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 7.76 GiB (GPU 0; 14.73 GiB total capacity; 8.34 GiB already allocated; 5.45 GiB free; 8.34 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQjnfgCHGWRs"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "This is straigthforward, we pick a user and find the movies not rated by the user. Convert the user and the list of non rated movies as tensors and then pass to the model to get the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p8bCnuLD83V",
        "outputId": "2aab96b4-06bd-437b-ed2f-f8c6dc262d14"
      },
      "source": [
        "# predict \n",
        "\n",
        "movies_ratedby_1 = data[data.userId == 1]['movieId'].values\n",
        "movies_notratedby_1 = list(set(data.movieId.values.tolist()) - set(movies_ratedby_1.tolist()))\n",
        "\n",
        "print(len(movies_ratedby_1), len(movies_notratedby_1))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "232 9492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQq2i155Fo6m",
        "outputId": "5ae3e788-ec0c-4ef0-ee09-7687747c74d8"
      },
      "source": [
        "# movies_notratedby_1[0:5]\n",
        "# [2, 4, 5, 7, 8]\n",
        "\n",
        "user = torch.LongTensor([1])\n",
        "items = torch.LongTensor([2, 4, 5, 7, 8])\n",
        "predicted_rating = model(user, items)\n",
        "print(predicted_rating)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4.2658, 4.4803, 4.4493, 3.6800, 3.9885], grad_fn=<SumBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZvl9Pe3IQpu",
        "outputId": "d6f04bd2-b8c6-47f3-8f01-4009325751ae"
      },
      "source": [
        "train_epocs(model, epochs=15, lr=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6432433128356934\n",
            "1.004770278930664\n",
            "0.711879551410675\n",
            "0.6606624126434326\n",
            "0.7254241108894348\n",
            "0.8038312792778015\n",
            "0.8437075614929199\n",
            "0.8357229828834534\n",
            "0.7934749722480774\n",
            "0.7378419041633606\n",
            "0.6878331899642944\n",
            "0.6556430459022522\n",
            "0.6445807218551636\n",
            "0.6497317552566528\n",
            "0.6612839698791504\n",
            "test loss 0.821 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUbOpStPIQpu",
        "outputId": "91b2d4ec-8eb7-4532-c89f-984e8274b639"
      },
      "source": [
        "train_epocs(model, epochs=15, lr=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6693901419639587\n",
            "0.6312034130096436\n",
            "0.6390069723129272\n",
            "0.614273190498352\n",
            "0.6052837371826172\n",
            "0.6137663722038269\n",
            "0.6116158366203308\n",
            "0.5968126058578491\n",
            "0.5848029255867004\n",
            "0.5829773545265198\n",
            "0.5840793251991272\n",
            "0.5791772603988647\n",
            "0.5685186386108398\n",
            "0.5582433342933655\n",
            "0.5519680380821228\n",
            "test loss 0.759 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbuW3Nw5Qqa_",
        "outputId": "f1b6ccc9-d91d-4999-8614-3fc5b9632829"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of MF_bias(\n",
              "  (user_emb): Embedding(610, 100)\n",
              "  (user_bias): Embedding(610, 1)\n",
              "  (item_emb): Embedding(8998, 100)\n",
              "  (item_bias): Embedding(8998, 1)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3_-GgxYRZl3",
        "outputId": "2fba4776-a182-426c-addf-15f060396e94"
      },
      "source": [
        "len(train.userId.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U9AQfCSRxPt"
      },
      "source": [
        "movies_watched = train[train.userId == 1].movieId.values\n",
        "movies_not_watched = list(set(train.movieId.values.flatten()) - set(movies_watched.flatten()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-HTSCtIQpu"
      },
      "source": [
        "## MF with bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czzIc_JaIQpu"
      },
      "source": [
        "class MF_bias(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100):\n",
        "        super(MF_bias, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.user_bias = nn.Embedding(num_users, 1)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.item_bias = nn.Embedding(num_items, 1)\n",
        "        self.user_emb.weight.data.uniform_(0,0.05)\n",
        "        self.item_emb.weight.data.uniform_(0,0.05)\n",
        "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
        "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        V = self.item_emb(v)\n",
        "        b_u = self.user_bias(u).squeeze()\n",
        "        b_v = self.item_bias(v).squeeze()\n",
        "        return (U*V).sum(1) +  b_u  + b_v"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1Fgq6UyIQpu"
      },
      "source": [
        "model = MF_bias(num_users, num_items, emb_size=100) #.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2vz_dwzIQpu",
        "outputId": "2271d706-7c67-427f-9f01-361a66a11497"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.05, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.908324241638184\n",
            "9.145543098449707\n",
            "4.37777853012085\n",
            "1.1558018922805786\n",
            "2.4738709926605225\n",
            "3.7419700622558594\n",
            "2.444751262664795\n",
            "1.0767680406570435\n",
            "0.8169639706611633\n",
            "1.3199241161346436\n",
            "test loss 2.070 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92YYbWGcIQpu",
        "outputId": "15b32f8a-5e8c-4f3b-83d1-c7f5cafea6f4"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.01, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.894714117050171\n",
            "1.3260996341705322\n",
            "0.9358387589454651\n",
            "0.7452532649040222\n",
            "0.7224956154823303\n",
            "0.7773878574371338\n",
            "0.8229359984397888\n",
            "0.8220500946044922\n",
            "0.7816600203514099\n",
            "0.7278069853782654\n",
            "test loss 0.798 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBKBYVnIQpu",
        "outputId": "de63671b-31fd-491b-c928-6417e82ba754"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6854904890060425\n",
            "0.6712726354598999\n",
            "0.6593731045722961\n",
            "0.6496144533157349\n",
            "0.6417774558067322\n",
            "0.635627269744873\n",
            "0.6309210658073425\n",
            "0.6274157762527466\n",
            "0.6248804330825806\n",
            "0.6231045126914978\n",
            "test loss 0.751 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWQMU-ARIQpu"
      },
      "source": [
        "Note that these models are susceptible to weight initialization, optimization algorithm and regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqh5o1XHIQpu"
      },
      "source": [
        "## Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UL-frTcIQpu"
      },
      "source": [
        "# Note here there is no matrix multiplication, we could potentially make the embeddings of different sizes.\n",
        "# Here we could get better results by keep playing with regularization.\n",
        "    \n",
        "class CollabFNet(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
        "        super(CollabFNet, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
        "        self.lin2 = nn.Linear(n_hidden, 1)\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        V = self.item_emb(v)\n",
        "        x = F.relu(torch.cat([U, V], dim=1))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        return x"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU4dH6KCIQpu"
      },
      "source": [
        "model = CollabFNet(num_users, num_items, emb_size=100) #.cuda()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3W4YSbgIQpu",
        "outputId": "8fa9465a-41e0-47c7-8e51-ce527b628c53"
      },
      "source": [
        "train_epocs(model, epochs=15, lr=0.05, wd=1e-6, unsqueeze=True) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.108604431152344\n",
            "5.802009105682373\n",
            "1.2773118019104004\n",
            "2.963860273361206\n",
            "2.6693785190582275\n",
            "1.3834798336029053\n",
            "1.1445742845535278\n",
            "1.8121241331100464\n",
            "1.5614513158798218\n",
            "0.9581654667854309\n",
            "0.9473393559455872\n",
            "1.2283742427825928\n",
            "1.2935713529586792\n",
            "1.0572116374969482\n",
            "0.7798777222633362\n",
            "test loss 0.828 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIl7Sy08IQpv",
        "outputId": "6d4284d4-a368-47f8-bd44-035456602a2d"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.01, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7271547317504883\n",
            "0.938242495059967\n",
            "0.888296902179718\n",
            "1.159741997718811\n",
            "1.1197892427444458\n",
            "0.9154775738716125\n",
            "0.7834805250167847\n",
            "0.7914189696311951\n",
            "0.8674263954162598\n",
            "0.9142893552780151\n",
            "test loss 0.938 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O95c3atIQpv",
        "outputId": "fe335bad-d1da-4660-b88e-2dc9b642604a"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8928335905075073\n",
            "0.8472162485122681\n",
            "0.8096950054168701\n",
            "0.7786527872085571\n",
            "0.7578306198120117\n",
            "0.7424415349960327\n",
            "0.7362892031669617\n",
            "0.7386234402656555\n",
            "0.7381541132926941\n",
            "0.7439978718757629\n",
            "test loss 0.797 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyN3dZalIQpv",
        "outputId": "f9e7e605-859c-442a-cdf3-42d9f36555c2"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6919353008270264\n",
            "0.6934647560119629\n",
            "0.6922585368156433\n",
            "0.6942275762557983\n",
            "0.6926798224449158\n",
            "0.6916202902793884\n",
            "0.6911264061927795\n",
            "0.6923496127128601\n",
            "0.6922929286956787\n",
            "0.6904215812683105\n",
            "test loss 0.795 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}